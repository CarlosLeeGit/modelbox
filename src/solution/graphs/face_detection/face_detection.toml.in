[graph]
graphconf = '''digraph demo {
    video_input[type=flowunit, flowunit=video_input, device=cpu, deviceid=0, label="<stream_meta>", source_url="@SOLUTION_VIDEO_DIR@/face_test.mp4"]
    videodemuxer[type=flowunit, flowunit=video_demuxer, device=cpu, deviceid=0, label="<in_video_url> | <out_video_packet>"]
    videodecoder[type=flowunit, flowunit=video_decoder, device=cpu, deviceid=0, queue_size=16, batch_size=5, label="<in_video_packet> | <out_video_frame>", pix_fmt=rgb]
    face_preprocess[type=flowunit, flowunit=face_preprocess, device=cpu, deviceid=0, queue_size=16, batch_size=5, method=inter_nearest, width=640, resize_type=1, height=352, label="<In_1> | <Out_1>"]
    face_color_transpose[type=flowunit, flowunit=face_color_transpose, device=cpu, deviceid=0, queue_size=16, batch_size=5, label="<in_image> | <out_image>"]
    face_inference[type=flowunit, flowunit=face_inference, device=cuda, deviceid=0, queue_size=16, batch_size=5, label="<blob1> | <sigmoid_blob1> | <conv_blob60> | <conv_blob62> | <conv_blob64>"]
    face_center[type=flowunit, flowunit=face_center, device=cpu, deviceid=0, queue_size=16, batch_size=5, input_height=352, input_width=640, image_height=1440, image_width=2560, label="<sigmoid_blob1> | <conv_blob60> | <conv_blob62> | <conv_blob64> | <Out_1> | <Out_2>"]
    face_alignment[type=flowunit, flowunit=face_alignment, device=cpu, deviceid=0, queue_size=16, batch_size=5, net_width=224, net_height=224, label="<In_img> | <In_kps> | <Aligned_img>"]
    face_expand[type=flowunit, flowunit=face_expand, device=cpu, deviceid=0, label="<In_img> | <Out_img>"]
    face_condition[type=flowunit, flowunit=face_condition, device=cpu, deviceid=0, queue_size=16, batch_size=1, label="<In_img> | <Out_true> | <Out_false>"]
    expression_inference[type=flowunit, flowunit=expression_inference, device=cuda, deviceid=0, queue_size=16, batch_size=5, label="<blob1> | <fc_blob1>"]
    expression_process[type=flowunit, flowunit=face_mobilev2, device=cpu, deviceid=0, queue_size=16, batch_size=5, label="<fc_blob1> | <Out_1>"]
    face_collapse[type=flowunit, flowunit=face_collapse, device=cpu, deviceid=0, label="<In_label> | <Out_label>"]
    face_draw[type=flowunit, flowunit=face_draw, device=cpu, deviceid=0, queue_size=16, batch_size=5, method=max, label="<In_1> | <In_2> | <In_3> | <Out_1>"]
    videoencoder[type=flowunit, flowunit=video_encoder, device=cpu, deviceid=0, queue_size=16, encoder=mpeg4, default_dest_url="rtsp://localhost/test", label="<in_video_frame>"]

    video_input:out_video_url -> videodemuxer:in_video_url
    videodemuxer:out_video_packet -> videodecoder:in_video_packet
    videodecoder:out_video_frame -> face_preprocess:In_1
    videodecoder:out_video_frame -> face_alignment:In_img
    videodecoder:out_video_frame -> face_draw:In_2
    face_preprocess:Out_1 -> face_color_transpose:in_image
    face_color_transpose:out_image -> face_inference:blob1
    face_inference:sigmoid_blob1 -> face_center:sigmoid_blob1
    face_inference:conv_blob60 -> face_center:conv_blob60
    face_inference:conv_blob62 -> face_center:conv_blob62
    face_inference:conv_blob64 -> face_center:conv_blob64
    face_center:Out_2 -> face_alignment:In_kps
    face_center:Out_1 -> face_draw:In_1
    face_alignment:Aligned_img -> face_expand:In_img
    face_expand:Out_img -> face_condition:In_img
    face_condition:Out_true -> expression_inference:blob1
    face_condition:Out_false -> face_collapse:In_label
    expression_inference:fc_blob1 -> expression_process:fc_blob1
    expression_process:Out_1 -> face_collapse:In_label
    face_collapse:Out_label -> face_draw:In_3
    face_draw:Out_1 -> videoencoder:in_video_frame
}
'''
format = "graphviz"
[driver]
dir = [
"@SOLUTION_FLOWUNIT_TRAFFIC_DIR@",
]
[flow]
desc = "expression detection for video streams"